{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c361c84-78b0-4656-9e4a-4e61a27061f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.4\\Lib\\site-packages\\catboost\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001b[0;32m      3\u001b[0m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001b[0;32m      4\u001b[0m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001b[0;32m      5\u001b[0m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001b[0;32m      6\u001b[0m )  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VERSION \u001b[38;5;28;01mas\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeaturesData\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFstrType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEShapCalcType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionAlgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEFeaturesSelectionGrouping\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPool\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoostRanker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatboostError\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomMetric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiTargetCustomObjective\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m ]\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.4\\Lib\\site-packages\\catboost\\core.py:45\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuiltinMetric\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.4\\Lib\\site-packages\\catboost\\plot_helpers.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _catboost\n\u001b[0;32m      6\u001b[0m fspath \u001b[38;5;241m=\u001b[39m _catboost\u001b[38;5;241m.\u001b[39mfspath\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_plot_offline\u001b[39m(figs):\n",
      "File \u001b[1;32m_catboost.pyx:1\u001b[0m, in \u001b[0;36minit _catboost\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List\n",
    "import catboost as cb\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "from configs.config import settings\n",
    "from models.model_validator import create_validator\n",
    "from utils.basic_utils import save_pickle, save_shap, save_toml\n",
    "\n",
    "train_data = 'D:\\python\\1_Internship\\scoring_pipeline\\data\\congo_featuretools1807_prepared.parquet'\n",
    "\n",
    "class Tuning:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_train: pd.DataFrame,\n",
    "        y_train: pd.Series,\n",
    "        X_test: pd.DataFrame,\n",
    "        y_test: pd.Series,\n",
    "    ) -> None:\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "        self.feature_list = settings.FEATURES.feature_list\n",
    "        self.cat_feature_list = settings.FEATURES.cat_feature_list\n",
    "\n",
    "    def objective(self, trial, optimal_difference) -> float:\n",
    "        params = {}\n",
    "        list_params = ['bootstrap_type', 'boosting_type']\n",
    "        int_params = ['depth', 'n_estimators']\n",
    "\n",
    "        for param in settings.HYPERPARAMETERS.tuning:\n",
    "            if param in list_params:\n",
    "                params[param] = trial.suggest_categorical(\n",
    "                    param, settings.HYPERPARAMETERS.tuning[param]\n",
    "                )\n",
    "            elif param in int_params:\n",
    "                params[param] = trial.suggest_int(\n",
    "                    param,\n",
    "                    settings.HYPERPARAMETERS.tuning[param][0],\n",
    "                    settings.HYPERPARAMETERS.tuning[param][1],\n",
    "                )\n",
    "            elif param == 'l2_leaf_reg':\n",
    "                start, end, step = settings.HYPERPARAMETERS.tuning[param]\n",
    "                params[param] = trial.suggest_float(param, start, end, step=step)\n",
    "            elif param == 'learning_rate':\n",
    "                start, end = settings.HYPERPARAMETERS.tuning[param]\n",
    "                params[param] = trial.suggest_float(param, start, end)\n",
    "            else:\n",
    "                params[param] = trial.suggest_float(\n",
    "                    param,\n",
    "                    settings.HYPERPARAMETERS.tuning[param][0],\n",
    "                    settings.HYPERPARAMETERS.tuning[param][1],\n",
    "                )\n",
    "\n",
    "        model = cb.CatBoostClassifier(\n",
    "            **params,\n",
    "            random_seed=settings.HYPERPARAMETERS.random_seed,\n",
    "            cat_features=self.cat_feature_list,\n",
    "            verbose=False,\n",
    "        )\n",
    "        model.fit(self.X_train, self.y_train, eval_set=(self.X_test, self.y_test), early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "        train_auc = (\n",
    "            roc_auc_score(self.y_train, model.predict_proba(self.X_train)[:, 1]) * 100\n",
    "        )\n",
    "        test_auc = (\n",
    "            roc_auc_score(self.y_test, model.predict_proba(self.X_test)[:, 1]) * 100\n",
    "        )\n",
    "        difference = abs(train_auc - test_auc)\n",
    "        difference_penalty = abs(difference - optimal_difference)\n",
    "        penalty_weight = 3\n",
    "\n",
    "        obj_val = test_auc - (difference_penalty ** penalty_weight)\n",
    "\n",
    "        logging.info(f\"\\n>>> Train AUC: {train_auc}, Test AUC: {test_auc}, Difference: {difference} <<<\")\n",
    "        return obj_val\n",
    "\n",
    "    def optimize_hyperparameters(self) -> Dict[str, Any]:\n",
    "        mx_test_auc, final_params = 0, None\n",
    "\n",
    "        for optimal_difference in range(3, 7):\n",
    "            study = optuna.create_study(direction='maximize')\n",
    "            study.optimize(\n",
    "                lambda trial: self.objective(trial, optimal_difference), n_trials=30\n",
    "            )\n",
    "\n",
    "            best_params = study.best_params\n",
    "            model = cb.CatBoostClassifier(\n",
    "                **best_params,\n",
    "                random_seed=settings.HYPERPARAMETERS.random_seed,\n",
    "                cat_features=self.cat_feature_list,\n",
    "                verbose=False,\n",
    "            )\n",
    "            model.fit(self.X_train, self.y_train, verbose=False)\n",
    "\n",
    "            train_auc = (\n",
    "                    roc_auc_score(self.y_train, model.predict_proba(self.X_train)[:, 1])\n",
    "                    * 100\n",
    "            )\n",
    "            test_auc = (\n",
    "                    roc_auc_score(self.y_test, model.predict_proba(self.X_test)[:, 1]) * 100\n",
    "            )\n",
    "            logging.info(\n",
    "                f\"#### Optimal Difference {optimal_difference}, Train AUC: {train_auc}, Test AUC: {test_auc} ####\\n\\n\"\n",
    "            )\n",
    "\n",
    "            if test_auc > mx_test_auc and (final_params is None or abs(train_auc - test_auc) <= 6):\n",
    "                mx_test_auc = test_auc\n",
    "                final_params = best_params\n",
    "                logging.info(f\"New optimal parameters found: {final_params}\")\n",
    "                logging.info(\n",
    "                    f\"Optimal Test AUC: {test_auc}, Train AUC: {train_auc}, Difference: {abs(train_auc - test_auc)}\")\n",
    "\n",
    "        logging.info(f\"Final optimal parameters: {final_params}\")\n",
    "        logging.info(f\"Final optimal Test AUC: {mx_test_auc}\")\n",
    "\n",
    "        return final_params\n",
    "\n",
    "def fit(df: pd.DataFrame, run_time, model_path, run_iteration) -> cb.CatBoostClassifier:\n",
    "    \"\"\"\n",
    "    This function splits the input dataframe into train and test, initializes\n",
    "    a CatBoostClassifier and fits it on the train data while evaluating on the test data then save the model artifact.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): main_sample df with defined factors and is_train bool.\n",
    "\n",
    "    Returns:\n",
    "        object: The trained CatBoost model\n",
    "    \"\"\"\n",
    "\n",
    "    feature_list = settings.FEATURES.feature_list\n",
    "    cat_feature_list = settings.FEATURES.cat_feature_list\n",
    "\n",
    "    # split into train and test\n",
    "    X_train = df.loc[df['is_train'] == 1].reset_index(drop=True)[feature_list]\n",
    "    y_train = df.loc[df['is_train'] == 1, ['target']].reset_index(drop=True)\n",
    "\n",
    "    X_test = df.loc[df['is_train'] == 0].reset_index(drop=True)[feature_list]\n",
    "    y_test = df.loc[df['is_train'] == 0, ['target']].reset_index(drop=True)\n",
    "\n",
    "    # init model and fit\n",
    "    logging.info('------- Fitting the model...')\n",
    "\n",
    "    if settings.TUNING.enabled:\n",
    "        tuning_obj = Tuning(X_train, y_train, X_test, y_test)\n",
    "        best_params = tuning_obj.optimize_hyperparameters()\n",
    "        settings.HYPERPARAMETERS.training = best_params\n",
    "\n",
    "    # Проверяем, включена ли кросс-валидация\n",
    "    if settings.MODEL.Cross_validation_enabled:\n",
    "        auc_scores = cross_validation(df, settings.HYPERPARAMETERS.training)\n",
    "        logging.info(f'Cross-validation AUC scores: {auc_scores}')\n",
    "        logging.info(f'Mean Cross-validation AUC: {np.mean(auc_scores)}')\n",
    "\n",
    "    cbm = cb.CatBoostClassifier(\n",
    "        **settings.HYPERPARAMETERS.training,\n",
    "        random_seed=settings.HYPERPARAMETERS.random_seed,\n",
    "        cat_features=cat_feature_list,\n",
    "        verbose=False,\n",
    "    )\n",
    "    cbm.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, cbm.predict_proba(X_train)[:, 1]) * 100\n",
    "    test_auc = roc_auc_score(y_test, cbm.predict_proba(X_test)[:, 1]) * 100\n",
    "    difference = abs(train_auc - test_auc)\n",
    "\n",
    "    logging.info(f\"Final model training complete.\")\n",
    "    logging.info(f\"Final parameters: {settings.HYPERPARAMETERS.training}\")\n",
    "    logging.info(f\"Train AUC: {train_auc}, Test AUC: {test_auc}, Difference: {difference}\")\n",
    "\n",
    "    # create a timestamp for the current run\n",
    "\n",
    "    # create the directory for the current run\n",
    "    run_dir = os.path.join(os.getcwd(), settings.PATHS.artifacts, f'run_{run_iteration}')\n",
    "    model_artifact_dir = f'{run_dir}/model_artifact'\n",
    "    try:\n",
    "        create_validator(\n",
    "            model_artifact_dir,\n",
    "            df[settings.FEATURES.feature_list],\n",
    "            'target',\n",
    "            'variable_validator',\n",
    "        )\n",
    "        save_toml(model_artifact_dir)\n",
    "        # save model in pickle file\n",
    "        save_pickle(cbm, model_path)\n",
    "        logging.info('------- Model saved...')\n",
    "    except OSError:\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        os.makedirs(model_artifact_dir)\n",
    "        shap_path = f'{model_artifact_dir}/{settings.METADATA.model_name}_explainer.bz2'\n",
    "        create_validator(\n",
    "            model_artifact_dir,\n",
    "            df[settings.FEATURES.feature_list],\n",
    "            'target',\n",
    "            'variable_validator',\n",
    "        )\n",
    "        save_toml(model_artifact_dir)\n",
    "        # save model in pickle file\n",
    "        save_pickle(cbm, model_path)\n",
    "        logging.info('------- Model saved...')\n",
    "\n",
    "        save_shap(cbm, shap_path)\n",
    "        logging.info('------- Shap explainer saved...')\n",
    "    return cbm\n",
    "\n",
    "def cross_validation(\n",
    "        df: pd.DataFrame, model_params: Dict[str, Any], n_splits: int = 5, random_state: int = 42\n",
    "    ) -> List[float]:\n",
    "    \"\"\"\n",
    "    Perform cross-validation using CatBoostClassifier.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing all features and the target variable.\n",
    "    model_params (Dict[str, Any]): Parameters to be used for CatBoostClassifier.\n",
    "    n_splits (int): Number of splits for cross-validation.\n",
    "    random_state (int): Random state for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    List[float]: List of AUC scores for each fold.\n",
    "\n",
    "    This function performs k-fold cross-validation using CatBoostClassifier and returns the AUC scores for each fold.\n",
    "    \"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    auc_scores = []\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfece50e-16db-48b0-b337-e90d85fb4256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
